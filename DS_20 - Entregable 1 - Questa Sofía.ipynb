{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "38tA-ErIC4OD"
   },
   "source": [
    "# Proyecto: Análisis de mercado inmobiliario\n",
    "\n",
    "¡Bienvenido/a al primer proyecto de la carrera de Data Science de Acamica! \n",
    "\n",
    "El objetivo de este proyecto es reproducir los pasos que haría un/a Data Scientist cuando se enfrenta a una problemática real. Por eso, consta de tres secciones:\n",
    "* En la Parte 1, te presentamos la problemática sobre la cual vas a trabajar. En esta sección deberás decidir qué datos te ayudarán a trabajar en este problema y dónde puedes conseguirlos.\n",
    "* En la Parte 2 te proveemos de un dataset para abordar la problemática planteada. Deberás realizar un Análisis Exploratorio de Datos sobre este dataset.\n",
    "* En la Parte 3, deberás utilizar herramientas de Machine Learning para predecir la variable de interés.\n",
    "\n",
    "\n",
    "En este proyecto vas a trabajar con un dataset de propiedades en venta publicado en el portal [Properati](www.properati.com.ar).\n",
    "\n",
    "## Problema\n",
    "\n",
    "Recientemente te has incorporado al equipo de Datos de una gran inmobiliaria. La primera tarea que se te asigna es ayudar a los tasadores/as a valuar las propiedades, ya que es un proceso difícil y, a veces, subjetivo. Para ello, propones crear un modelo de Machine Learning que, dadas ciertas características de la propiedad, prediga su precio de venta.\n",
    "\n",
    "### 1. Pensando como un/a Data Scientist\n",
    "\n",
    "Responde la siguientes pregunta:\n",
    "1. ¿Qué datos crees que te ayudarían a trabajar en el problema?¿Por qué?\n",
    "\n",
    "**Importante**: NO deberás buscar esos datos, solamente justificar qué información crees que te ayudaría a resolver la problemática planteada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Datos que podrían ayudar a trabajar en el problema:\n",
    "\n",
    "• Tipo de propiedad \n",
    "\n",
    "• Tamaño en m2 cubiertos\n",
    "\n",
    "• Tamaño en m2 total\n",
    "\n",
    "• Cocheras\n",
    "\n",
    "• Piscina\n",
    "\n",
    "• Amoblamiento\n",
    "\n",
    "• Vistas\n",
    "\n",
    "• Cantidad de ambientes\n",
    "\n",
    "• Antigüedad \n",
    "\n",
    "• Provincia\n",
    "\n",
    "• Localidad\n",
    "\n",
    "• Distrito\n",
    "\n",
    "• % Contaminación ambiental\n",
    "\n",
    "• Cercanía a lugares turísticos\n",
    "\n",
    "• Cercanía a zonas comerciales\n",
    "\n",
    "##### Estas características le agregan valor a una propiedad y por ende influyen en el precio de las mismas, es por ello que las puedo considerar a la hora de estimar precios.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LvPBQzg5C4OI"
   },
   "source": [
    "---\n",
    "## 2. Análisis Exploratorio de Datos\n",
    "---\n",
    "##### En esta sección, debes realizar un Análisis Exploratorio de Datos sobre el dataset de propiedades de Properati. Es importante que respondas las siguientes preguntas durante el análisis:\n",
    "\n",
    "* ¿Qué tamaño tiene el dataset?¿Cuántas instancias y cuántas columnas?\n",
    "* ¿Cuántos valores faltantes hay en cada columna?\n",
    "* ¿Cómo es la distribución de cada variable? Deberás hacer histogramas para las variables numéricas y gráficos de barras para las variables categóricas.\n",
    "* ¿Cómo se relacionan las variables entre sí? ¿Qué tipo de gráfico será conveniente para presentar esta información? \n",
    "* ¿Cómo están correlacionadas las variables numéricas?¿Qué tipo de gráfico será conveniente para presentar esta información? ¿Cuáles serán los mejores predictores de la variable de interés? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Importa las librerías necesarias para trabajar en la consigna."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Carga el dataset usando las funcionalidades de Pandas. Imprimir cuántas filas y columnas tiene, y sus cinco primeras instancias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_prop = pd.read_csv('DS_Proyecto_01_Datos_Properati.csv')\n",
    "display(Markdown('##### El dataset de Properati tiene `' + str(ds_prop.shape[0]) + '` instancias y `' + str(ds_prop.shape[1]) + \"\"\"` columnas.\n",
    "\n",
    "##### Las primeras cinco instancias son las siguientes: \"\"\"))\n",
    "display(ds_prop.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown('##### Las columnas del dataset son las siguientes: '))\n",
    "display(pd.DataFrame(ds_prop.columns, columns = ['Nombre de columna'], index = np.arange(1,20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Las variables que considero de interés para estudiar son:\n",
    "- `l1`, `l2`, `l3`: que tratan acerca de la ubicación de la propiedad\n",
    "- `rooms`, `bedrooms`, `bathrooms`, `surface_covered`, `surface_total`: que son características de la propiedad\n",
    "- `price`, `currency`: tratan acerca del precio y cómo está valuada la propiedad\n",
    "- `property_type`: tipo de propiedades que se encuentran disponibles\n",
    "- `operation_type`: tipo de operación para cada propiedad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown('##### Los tipos de datos que tenemos en las columnas del dataset son los siguientes:'))\n",
    "display(pd.DataFrame(ds_prop.dtypes, columns = ['Tipos de datos']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los tipos de datos que se encuentran en el dataset son: `float64` y `object`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown('#### Gráficos de distribución de variables: '))\n",
    "display(Markdown('##### Grafico sólo las variables que describí como variables de interés'))\n",
    "aux = pd.DataFrame(ds_prop.iloc[:,5:]) # No me interesan las 5 primeras columnas\n",
    "\n",
    "ds_prop_obj = pd.DataFrame(aux.select_dtypes(include = ['object']))\n",
    "ds_prop_obj = pd.DataFrame(aux[['l1', 'l2', 'l3', 'currency', 'property_type', 'operation_type']])\n",
    "\n",
    "ds_prop_float = pd.DataFrame(aux.select_dtypes(include = ['float64']))\n",
    "\n",
    "k = 1\n",
    "j = ds_prop_obj.shape[1]\n",
    "plt.figure(figsize=(18, 6*j))\n",
    "with sns.axes_style('whitegrid'):\n",
    "    for i in range(0, j):\n",
    "        plt.subplot(j, 1, k)\n",
    "        plt.title('Countplot de: ' + ds_prop_obj.columns[i], fontdict = {'fontsize':18})\n",
    "        sns.countplot(x = ds_prop_obj.columns[i], data = ds_prop_obj, order = ds_prop_obj[ds_prop_obj.columns[i]].value_counts().sort_values(ascending = False).index, palette = 'Spectral', edgecolor = 'k')\n",
    "        plt.xlabel(ds_prop_obj.columns[i],fontdict = {'fontsize':14})\n",
    "        plt.ylabel('N° de instancias', fontdict = {'fontsize':14})\n",
    "        plt.xticks(rotation = 90)\n",
    "        plt.tick_params(labelsize = 'large')\n",
    "        k += 1\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    k = 1\n",
    "    j = ds_prop_float.shape[1]\n",
    "    plt.figure(figsize=(18, 6*j))\n",
    "    sns.set_palette('Set1')\n",
    "    for i in range(0, j):\n",
    "        plt.subplot(j, 1, k)\n",
    "        plt.title('Histograma de: ' + ds_prop_float.columns[i], fontdict = {'fontsize':18})\n",
    "        sns.distplot(ds_prop_float[ds_prop_float.columns[i]], hist_kws = {'edgecolor':'k'}, kde = False)\n",
    "        plt.xlabel(ds_prop_float.columns[i], fontdict = {'fontsize':14})\n",
    "        plt.ylabel('N° de instancias', fontdict = {'fontsize':14})\n",
    "        plt.tick_params(labelsize = 'large')\n",
    "        k += 1\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ds_prop_float.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A partir de una rápida observación de los gráficos se puede ver que:\n",
    "- El dataset tiene únicamente propiedades de Argentina, y dentro de Argentina solamente se está considerando Capital Federal y distintas zonas de G.B.A.\n",
    "- La mayoría de las propiedades se encuentran en Capital Federal\n",
    "- El barrio con mayor concentración de propiedades se encuentra dentro de Capital Federal y es Palermo\n",
    "- Las propiedades están tasadas únicamente en dólares y el dataset contiene sólo información de ventas\n",
    "- La mayoría de las propiedades corresponden a departamentos\n",
    "- Las variables de precio, superficie cubierta y superficie total tienen valores extremos y gran variabilidad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Valores Faltantes**: imprime en pantalla los nombres de las columnas y cuántos valores faltantes hay por columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_faltantes = pd.DataFrame(ds_prop.isna().sum(), columns = ['Valores faltantes'])\n",
    "ds_faltantes['Nombre de columna'] = ds_faltantes.index\n",
    "ds_faltantes.index = np.arange(1,20)\n",
    "ds_faltantes = ds_faltantes[['Nombre de columna', 'Valores faltantes']]\n",
    "ds_faltantes['Porcentaje'] = round(ds_faltantes['Valores faltantes']/ [ds_prop.shape[0]] * 100,2)\n",
    "display(ds_faltantes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dentro de las variables consideradas ` de interés`, las que poseen valores faltantes son: \n",
    "- `bathrooms`, ` surface_total`, ` surface_covered` \n",
    "\n",
    "Los valores faltantes de estas dos últimas variables representan un 14% de los datos disponibles en el DataSet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "ds_faltantes2 = ds_prop.isnull()\n",
    "sns.heatmap(ds_faltantes2,cmap ='viridis',)\n",
    "plt.title('Mapa de calor de valores nulos')\n",
    "plt.xlabel('Variables del DataSet')\n",
    "plt.ylabel('Instancias del DataSet')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el mapa de calor se pueden ver dónde están ubicadas las instancias con valores nulos (las de color amarillo).\n",
    "-  Fijando la atención sólo en las variable de interés, se puede notar que la mayoría de los valores nulos para los tres features (`bathrooms, surface_covered y surface_total`) se encuentran en las mismas instancias, por lo que no estamos eliminando una gran cantidad de datos del DataSet al hacer la limpieza de las mismas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Tipos de propiedad**: ¿Cuántos tipos de propiedad hay publicados según este dataset?¿Cuántos instancias por cada tipo de propiedad hay en el dataset? Responde esta pregunta usando las funcionalidad de Pandas y con un gráfico apropiado de Seaborn. **Pistas**: Te puede ser útil googlear cómo rotar las etiquetas del eje x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown('##### Cantidad de diferentes tipos de propiedades: '+ str(ds_prop['property_type'].nunique())))\n",
    "display(Markdown('Las mismas son: '))\n",
    "array = ds_prop['property_type'].unique()\n",
    "for i in range(0,10):\n",
    "    display(Markdown('###### • '+ str(array[i])))\n",
    "plt.figure(figsize=(18,6))\n",
    "with sns.axes_style('whitegrid'):\n",
    "    sns.countplot(x = 'property_type', data = ds_prop, order = ds_prop['property_type'].value_counts().sort_values(ascending = False).index, palette = 'Spectral', edgecolor = 'k')\n",
    "    plt.xlabel('Tipos de propiedades', fontdict = {'fontsize':14})\n",
    "    plt.ylabel('N° de instancias', fontdict = {'fontsize':14})\n",
    "    plt.title('Cantidad de cada tipo de propiedad', fontdict = {'fontsize':18})\n",
    "    plt.tick_params(labelsize = 'large', rotation = 45)\n",
    "    plt.grid()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown('- Como en el gráfico anterior no se pueden visualizar los datos de la mayoría de las columnas, entonces grafico en escala logarítmica.'))\n",
    "fig, ax = plt.subplots(figsize=(18,6))\n",
    "with sns.axes_style('whitegrid'):\n",
    "    sns.countplot(x = 'property_type', data = ds_prop, order = ds_prop['property_type'].value_counts().sort_values(ascending = False).index, palette = 'Spectral', edgecolor = 'k')\n",
    "    plt.xlabel('Tipos de propiedades', fontdict = {'fontsize':14})\n",
    "    plt.ylabel('N° de instancias [log scale]', fontdict = {'fontsize':14})\n",
    "    plt.title('Cantidad de cada tipo de propiedad', fontdict = {'fontsize':18})\n",
    "    ax.set_yscale('log')\n",
    "    plt.tick_params(labelsize = 'large', rotation = 45)\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar claramente que los tipos de propiedades más frecuentes o con mayor cantidad de intancias son:\n",
    "- Departamento\n",
    "- Casa\n",
    "- PH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,6))\n",
    "with sns.axes_style('whitegrid'):\n",
    "    sns.countplot(x = 'property_type', hue = 'l2', data = ds_prop, order = ds_prop['property_type'].value_counts().sort_values(ascending = False).index, palette = 'Dark2', edgecolor = 'k')\n",
    "    plt.xlabel('Tipos de propiedades', fontdict = {'fontsize':14})\n",
    "    plt.ylabel('N° de instancias', fontdict = {'fontsize':14})\n",
    "    plt.title('Cantidad de cada tipo de propiedad estratificada por región', fontdict = {'fontsize':18})\n",
    "    plt.tick_params(labelsize = 'large', rotation = 45)\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown('- Como en el gráfico anterior no se pueden visualizar los datos de la mayoría de las columnas, entonces grafico en escala logarítmica.'))\n",
    "fig, ax = plt.subplots(figsize=(18,6))\n",
    "with sns.axes_style('whitegrid'):\n",
    "    ax.set_yscale('log')\n",
    "    sns.countplot(x = 'property_type', hue = 'l2', data = ds_prop, order = ds_prop['property_type'].value_counts().sort_values(ascending = False).index, palette = 'Dark2', edgecolor = 'k')\n",
    "    plt.xlabel('Tipos de propiedades', fontdict = {'fontsize':14})\n",
    "    plt.ylabel('N° de instancias [log scale]', fontdict = {'fontsize':14})\n",
    "    plt.title('Cantidad de cada tipo de propiedad estratificada por región', fontdict = {'fontsize':18})\n",
    "    plt.tick_params(labelsize = 'large', rotation = 45)\n",
    "    plt.grid()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = pd.DataFrame(data = ds_prop['property_type'].value_counts())\n",
    "vc = vc.rename(columns = {'property_type':'Instancias por tipo de propiedad'})\n",
    "vc['% del total'] = round((vc['Instancias por tipo de propiedad']/vc['Instancias por tipo de propiedad'].sum())*100,2)\n",
    "vc_1 = vc\n",
    "display(Markdown('***Cantidad de instancias del dataset según tipo de propiedad:***'))\n",
    "display(vc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede concluir que el tipo de `propiedad más frecuente` dentro del dataset es **departamento** y que la mayoría de las propiedades están concentradas en Capital Federal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. ¿De qué regiones son las publicaciones? Haz gráficos de barras para las variables `l2` y `l3`. Si te animas, puedes hacer los dos gráficos usando `subplot` de Matplotlib. Dale un tamaño apropiado a la figura para que ambos gráficos se visualicen correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown('#### Regiones de las publicaciones: '))\n",
    "fig, ax = plt.subplots(figsize = (18,6))\n",
    "#ax.set_yscale('log')\n",
    "sns.countplot(y = 'l2', data = ds_prop, edgecolor = 'k', palette = 'PuRd', order = ds_prop['l2'].value_counts().sort_values(ascending = False).index, ax = ax)\n",
    "plt.ylabel('Regiones', {'fontsize':14})\n",
    "plt.xlabel('N° de instancias', {'fontsize': 14})\n",
    "plt.title('N° de intancias por Regiones', {'fontsize':18})\n",
    "plt.grid()\n",
    "\n",
    "\n",
    "for p in ax.patches:\n",
    "    x=p.get_bbox().get_points()[:,0]\n",
    "    y=p.get_bbox().get_points()[1,1]\n",
    "    ax.annotate(int(x[1]), (x.mean(), y), ha='left', va='bottom', fontsize = 14) #, rotation = 45, color = 'w')\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (18,12))\n",
    "ax.set_xscale('log')\n",
    "sns.countplot(y = 'l2', data = ds_prop, order = ds_prop['l2'].value_counts().sort_values(ascending = False).index, hue = 'property_type', edgecolor = 'k', palette = 'Paired')\n",
    "plt.xlabel('Cantidad de propiedades [log scale]', {'fontsize':14})\n",
    "plt.ylabel('Regiones', {'fontsize':14})\n",
    "plt.title('Tipos de propiedades por región', {'fontsize':18})\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.unique(ds_prop['l2'].values)\n",
    "for element in array:\n",
    "    vc = pd.DataFrame(data = ds_prop[ds_prop['l2'] == element]['property_type'].value_counts())\n",
    "    vc = vc.rename(columns = {'property_type':'Cantidad'})\n",
    "    vc['% del total en '+element] = round((vc['Cantidad']/vc['Cantidad'].sum())*100,2)\n",
    "    display(Markdown('#### Tipos de propiedad en: `' + element+'`'))\n",
    "    display(vc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A excepción de Capital Federal, en el resto de las regiones los tipos de propiedad en venta más frecuentes son:\n",
    "- `Departamento`y `Casa`\n",
    "\n",
    "En Capital Federal son:\n",
    "- `Departamento` y `PH`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown('#### Barrios de las publicaciones: '))\n",
    "fig, ax = plt.subplots(figsize = (21,6))\n",
    "sns.countplot(x = 'l3', data = ds_prop, order = ds_prop['l3'].value_counts().sort_values(ascending = False).index, edgecolor = 'k', ax = ax)\n",
    "plt.xlabel('Barrios', {'fontsize':14})\n",
    "plt.ylabel('N° de instancias', {'fontsize': 14})\n",
    "plt.title('N° de intancias por Barrios', {'fontsize':18})\n",
    "plt.xticks(rotation = 90)\n",
    "plt.grid()\n",
    "\n",
    "barrios = pd.DataFrame(ds_prop['l3'].value_counts())\n",
    "display((Markdown('##### Los 5 barrios con mayor cantidad de propiedades en venta son los siguientes:')))\n",
    "display(barrios.head(5))\n",
    "\n",
    "array = np.unique(ds_prop['l2'].values)\n",
    "k = 1\n",
    "j = round(array.shape[0]/2)\n",
    "plt.figure(figsize = (21,9*j))\n",
    "for element in array:\n",
    "    plt.subplot(j, 2, k)\n",
    "    k += 1\n",
    "    sns.countplot(x = 'l3', data = ds_prop[ds_prop['l2'] == element], order = ds_prop[ds_prop['l2'] == element]['l3'].value_counts().sort_values(ascending = False).index, edgecolor = 'k')\n",
    "    plt.xlabel('Barrios de la región '+ element, {'fontsize':14})\n",
    "    plt.ylabel('N° de instancias', {'fontsize': 14})\n",
    "    plt.title('N° de intancias por Barrios de la región ' + element, {'fontsize':18})\n",
    "    plt.xticks(rotation = 90, fontsize = 14)\n",
    "    plt.grid()\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Palermo llega a acumular tres veces la cantidad de propiedades en venta de los barrios con más propiedades de GBA Zona Sur y GBA Zona Oeste.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **Filtrando el Dataset:** A partir de los resultados del punto 3. y 4., selecciona las tres clases más abundantes de tipos de propiedad y la región con más propiedades publicadas. Crea un nuevo Data Frame con aquellas instancias que cumplen con esas condiciones e imprime su `shape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown('### • Las tres clases más abundantes son:'))\n",
    "display(vc_1.head(3))\n",
    "display(Markdown('### • La región con más propiedades publicadas es: ` Capital Federal` '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_prop = ds_prop.query(' l2 == \"Capital Federal\" & property_type in [\"Departamento\", \"Casa\", \"PH\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ds_prop.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint:** deberías tener un dataset con 91485 instacias, 19 columnas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "6. **Distribuciones y relaciones de a pares:** Estudia la distribución y las relaciones de a pares de las variables `rooms`, `bedrooms`, `bathrooms`, `surface_total`, `surface_covered`, `price` para cada tipo de propiedad. Para ello, ten en cuenta:\n",
    "    1. Obtiene estadísticos que te sirvan para tener una primera idea de los valores que abarcan estas variables. ¿Cuáles crees que toman valores que tal vez no tengan mucho sentido?\n",
    "    1. Algunas instancias tienen valores de superficie (`surface_total`) muy grandes y dificultan la correcta visualización. Estudia la distribución de esa variable y filtra por un valor razonable que te permita obtener gráficos comprensibles. Puede ser útil un boxplot para determinar un rango razonable.\n",
    "    1. Lo mismo ocurre con valores de superficie total muy chico.\n",
    "    1. Las propiedades no pueden tener `surface_covered` mayor a `surface_total`. Si eso sucede, debes filtrar esas instancias.\n",
    "    1. El rango de precios que toman las propiedades es muy amplio. Estudia la distribución de esa variable y filtra por un valor razonable que te permita obtener gráficos comprensibles. Puede ser útil un boxplot para determinar un rango razonable.\n",
    "    1. Una vez filtrado el dataset, puedes utilizar la función `pairplot` de Seaborn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ds_prop.drop(['lat','lon'], axis = 1).describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las variables `'rooms'`, `'bedrooms'`, `'bathrooms'` tienen baja variabilidad.\n",
    "\n",
    "Las variables `'surface_total'`, `'surface_covered'`, `'price'` tienen mucha variabilidad y parecieran tener valores extremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown('### Histogramas:'))\n",
    "lista = ['rooms', 'bedrooms', 'bathrooms', 'surface_total', 'surface_covered', 'price']\n",
    "j = 1\n",
    "plt.figure(figsize = (18,12))\n",
    "for element in lista:\n",
    "    plt.subplot(3,2,j)\n",
    "    j += 1\n",
    "    sns.distplot(ds_prop[element], kde = False, hist_kws = {'edgecolor':'k'}, color = 'r')\n",
    "    plt.grid(b = 1)\n",
    "    plt.title('Histograma de '+element)\n",
    "    plt.ylabel('Nro de instancias')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los histogramas de `surface_total, surface_covered, price` ya se puede notar que hay valores extremadamente altos, los cuales van a interferir con el análisis y predicción sino se filtran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown('### Boxplots:'))\n",
    "lista_1 = lista[:3]\n",
    "lista_2 = lista[3:5]\n",
    "lista_3 = lista[5:]\n",
    "plt.figure(figsize=(18,8))\n",
    "j = 1\n",
    "with sns.axes_style('whitegrid'):\n",
    "    for i in [lista_1, lista_2, lista_3]:\n",
    "        plt.subplot(2,2,j)\n",
    "        sns.boxplot(data = ds_prop[i], palette = 'RdPu')\n",
    "        j += 1\n",
    "     \n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los boxplot se puede observar:\n",
    "- Las variables `rooms, bedrooms, bathrooms` tienen valores atípicos (considerandolos así a los que están por fuera de los whiskers). Se podría optar por filtrarlos.\n",
    "- Las varibles `surface_total, surface_covered, price` tienen valores atípicos y son extremadamente altos. Se deberían filtrar para que no interfieran en el análisis y predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,8))\n",
    "j = 1\n",
    "with sns.axes_style('whitegrid'):\n",
    "    display(Markdown('### Violinplots:'))\n",
    "    for i in [lista_1, lista_2, lista_3]:\n",
    "        plt.subplot(2,2,j)\n",
    "        sns.violinplot(data = ds_prop[i], palette = 'RdPu')\n",
    "        j += 1\n",
    "     \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***Sin tener en cuenta las colas*** - La variable `rooms` pareciera tener una distribución normal, las variables `bedrooms` y `bathrooms` tienen un sesgo hacia los valores más pequeños.\n",
    "- No se pueden analizar las otras variables ya que sus valores extremos no permiten apreciar las distribuciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = ds_prop[lista].corr()\n",
    "display(Markdown('#### Correlación entre variables:'))\n",
    "display(corr)\n",
    "plt.figure(figsize = (10,10))\n",
    "sns.heatmap(corr, square = True, annot = True, alpha=0.75, cbar = True, cmap = 'RdPu')\n",
    "plt.tick_params(rotation = 45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***A priori*** pareciera que las variables que más correlacionadas están con la variable ***`price`*** son: `rooms`, `bedrooms`, `bathrooms`.\n",
    "\n",
    "##### ***Antes de realizar conclusiones***, debo filtrar las variables `surface_total`, `surface_covered`, `price`, y analizar su distribución y correlación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_prop[lista_2].quantile(q=np.arange(0,1.01, 0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtro como valor máximo los valores del cuantil en 0.9 para  `surface_total`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_prop_filt = ds_prop.query('surface_total <= 180')\n",
    "display(ds_prop_filt.shape)                             \n",
    "plt.figure(figsize = (18,8))\n",
    "plt.subplot(1,2,1)\n",
    "sns.distplot(ds_prop_filt[lista_2[0]], label = lista_2[0])\n",
    "sns.distplot(ds_prop_filt[lista_2[1]], label = lista_2[1])\n",
    "plt.title('Histograma')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "sns.boxplot(data = ds_prop_filt[lista_2]) \n",
    "plt.title('Boxplot')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede ver en el histograma y en el boxplot que los valores de `surface_covered` no han sido filtrados junto con `surface_total`. \n",
    "\n",
    "Lo que implica que no se cumple que  `surface_covered` **<=**`surface_total`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_prop_filt = ds_prop.query('surface_total <= 180 & surface_covered <= surface_total')\n",
    "display(ds_prop_filt.shape)\n",
    "plt.figure(figsize = (18,8))\n",
    "plt.subplot(1,2,1)\n",
    "sns.set_palette('Set2')\n",
    "sns.distplot(ds_prop_filt[lista_2[0]], bins = 50,  label = lista_2[0], color = 'm')\n",
    "sns.distplot(ds_prop_filt[lista_2[1]], bins = 50, label = lista_2[1], color = 'g')\n",
    "plt.title('Histograma')\n",
    "plt.xlabel('Metro cuadrados')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "sns.boxplot(data = ds_prop_filt[lista_2]) \n",
    "plt.title('Boxplot')\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_prop_filt[lista_2].quantile(q = np.arange(0, 1.01, 0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtro como mínimo de `surface_covered` = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_prop_filt = ds_prop_filt.query('surface_covered>=35')\n",
    "ds_prop_filt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown('#### Variables `surface_total` y `surface_covered` filtradas.'))\n",
    "plt.figure(figsize = (18,16))\n",
    "plt.subplot(2,2,1)\n",
    "sns.set_palette('Set2')\n",
    "sns.distplot(ds_prop_filt[lista_2[0]], bins = 50,  label = lista_2[0], color = 'm')\n",
    "sns.distplot(ds_prop_filt[lista_2[1]], bins = 50, label = lista_2[1], color = 'g')\n",
    "plt.title('Histograma')\n",
    "plt.xlabel('Metros cuadrados')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.subplot(2,2,2)\n",
    "sns.boxplot(data = ds_prop_filt[lista_2]) \n",
    "plt.title('Boxplot')\n",
    "plt.grid()\n",
    "plt.subplot(2,2,3)\n",
    "sns.violinplot(data = ds_prop_filt[lista_2]) \n",
    "plt.title('Violinplot')\n",
    "plt.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedo observar que los valores de `surface_total` y `surface_covered` se encuentran sesgados hacia la izquierda o los valores más pequeños de ambas variables. \n",
    "Para ambas variables el 50% de los valores pareciera acumularse entre 60 y 70 metros cuadrados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown('Luego de filtrados los datos de las variables `surface_covered` y `surface_total` vuelvo a observar las correlaciones entre las variables'))\n",
    "corr = ds_prop_filt[lista].corr()\n",
    "display(Markdown('#### Correlación entre variables:'))\n",
    "display(corr)\n",
    "plt.figure(figsize = (10,10))\n",
    "sns.heatmap(corr, square = True, annot = True, alpha=0.75, cbar = True, cmap = 'RdPu')\n",
    "plt.tick_params(rotation = 45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***A diferencia de lo obtenido anteriormente***, las variables que más correlacionadas están con la variable ***`price`*** son: `surface_total` y `surface_covered`. \n",
    "\n",
    "##### ***Antes de llegar a conclusiones***, debería filtrar todavía la variable `price` y analizarla."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.D\n",
    "\n",
    "El filtrado para que se cumpla la condición `surface_covered` **<=** `surface_total` ya se realizó en el apartado anterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_prop_filt[lista_3].quantile(q=np.arange(0.75 ,1.0, 0.025))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtro como valor máximo el valor del cuantil en 0.9 para `price`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_prop_filt = ds_prop_filt.query('price <= 375000')\n",
    "display(ds_prop_filt.shape)                             \n",
    "plt.figure(figsize = (18,8))\n",
    "plt.subplot(1,2,1)\n",
    "sns.distplot(ds_prop_filt[lista_3[0]], label = lista_3[0])\n",
    "plt.title('Histograma')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "sns.boxplot(data = ds_prop_filt[lista_3]) \n",
    "plt.title('Boxplot')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de realizar el filtrado superior de la variable `price` no se observan más valores atípicos. \n",
    "\n",
    "Igualmente, observo los valores mínimos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_prop_filt[lista_3].quantile(q=np.arange(0 , 0.275, 0.025))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtro como mínimo de `price` = 99000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown('#### Variable `price`filtrada.'))\n",
    "ds_prop_filt = ds_prop_filt.query('price>=99000')\n",
    "ds_prop_filt.shape\n",
    "plt.figure(figsize = (18,16))\n",
    "plt.subplot(2,2,1)\n",
    "sns.set_palette('Set2')\n",
    "sns.distplot(ds_prop_filt[lista_3[0]], bins = 50,  label = lista_3[0], color = 'm')\n",
    "plt.title('Histograma')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.subplot(2,2,2)\n",
    "sns.boxplot(data = ds_prop_filt[lista_3]) \n",
    "plt.title('Boxplot')\n",
    "plt.grid()\n",
    "plt.subplot(2,2,3)\n",
    "sns.violinplot(data = ds_prop_filt[lista_3]) \n",
    "plt.title('Violinplot')\n",
    "plt.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable `price` también se encuentra sesgada hacia la izquiera o los valores pequeños que toma. \n",
    "\n",
    "El 50% de los valores parece estar acumulado entre 165000 y 185000 U$D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown('Luego de filtrados los datos de la variable `price` vuelvo a observar las correlaciones entre las variables'))\n",
    "corr = ds_prop_filt[lista].corr()\n",
    "corr_eda = corr # lo uso en el desafio\n",
    "display(Markdown('#### Correlación entre variables:'))\n",
    "display(corr)\n",
    "plt.figure(figsize = (10,10))\n",
    "sns.heatmap(corr, square = True, annot = True, alpha=0.75, cbar = True, cmap = 'RdPu')\n",
    "plt.tick_params(rotation = 45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se nota aún más la correlación entre las variables `surface_total` y `surface_covered` con `price`.\n",
    "\n",
    "También se nota cierta correlación entre las varibles `rooms`, `bathrooms`, `bedrooms` con `price`, similar a la que había en el primer análisis.\n",
    "\n",
    "Otras variables altamente correlacionedas:\n",
    "- `rooms` y `bedrooms`\n",
    "- `surface_covered`y `surface_total`\n",
    "\n",
    "Se nota cierta correlación entre:\n",
    "- `rooms` y `surface_covered`\n",
    "- `surface_covered`y `bedrooms`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista.append('property_type') #Para estratificar el pairplot debo agregar a los features el de tipo de propiedad\n",
    "ds_prop_filt = ds_prop_filt[lista]\n",
    "ds_prop_filt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(' `Pairplot estratificado por tipo de propiedad` '))\n",
    "plt.figure(figsize=(20,24))\n",
    "with sns.axes_style('darkgrid'):\n",
    "    sns.pairplot(data = ds_prop_filt, hue = 'property_type', palette = 'Set1')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observaciones a partir del pairplot:\n",
    "\n",
    "- Variable `rooms`:  hay diferencia poco significativa entre los tipos departamento, ph y casa, siendo la cantidad de habitaciones menor en los departamentos\n",
    "- Variable `bedrooms`: hay diferencia poco significativa entre los tipos departamento, ph y casa, siendo la cantidad de dormitorios menor en los departamentos\n",
    "- No se nota diferencia significativa en la variable `bathrooms` para los diferentes tipos de propiedades\n",
    "- Varible `surface_covered`: para el tipo departamento los valores que toma esta variable se encuentran concetrados en los valores más pequeños o sesgados hacia la izquierda\n",
    "- Variable `surface_total`: para el tipo departamento los valores que toma esta variable se encuentran concetrados en los valores más pequeños o sesgados hacia la izquierda, y los valores más altos se encuentran concentrados en las casas o sesgados hacia la derecha\n",
    "- Variable `price`: toma similares valores para los departamentos y ph, concentrándose los valores más pequeños en estas clases\n",
    "\n",
    "##### El análisis de las correlaciones fue realizado en el apartado anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Desafío"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el dataset provisto hay mucha información, más allá del problema planteado. Propone una pregunta que pueda ser respondida por el dataset e intenta responderla.¿Cuáles son los sesgos de la respuesta obtenida?¿Cuán generalizable es la respuesta obtenida?)¿Necesitas información complementaria?¿Cómo la obtendrías?\n",
    "\n",
    "Por ejemplo: ¿Cuál es el barrio más caro de Buenos Aires? Probablemente puedas responder esta pregunta con este dataset. Pero podria ocurrir que la respuesta esté sesgada. ¿Cómo? Tal vez las propiedades más caras no se publican de forma online, sino que utilizan otro canal de venta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "A partir del análisis anterior se puede notar que hay diferencia entre algunas variables para cada tipo de propiedad y para cada barrio.\n",
    "\n",
    "`Para el desafío:`\n",
    "\n",
    "Voy a filtrar el dataset similar (redondeo algunos valores) a como lo filtré para el análisis:\n",
    "- surface_covered >= 30\n",
    "- surface_total <= 180\n",
    "- surface_covered <= surface_total\n",
    "- price <= 400000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `| Desafío propuesto:`\n",
    "##### Analizar si hay diferencia significativa entre los precios de las diferentes regiones y tipos de propiedades. De haber diferencia, analizar la zona más cara y tipo de propiedad más elevado. Luego, analizar y comparar las correlaciones entre variables con las obtenidas en el apartado anterior. Conclusiones.\n",
    "\n",
    "Para ello voy a definir tres categorías de precios:\n",
    "- `Bajos`: aquellos que se encuentren por debajo del 25% de los valores\n",
    "- `Medios` o normales: aquellos valores que se encuentren dentro del RIQ\n",
    "- `Altos` o elevados: aquellos que se encuentren por encima del 75% de los valores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Carga y filtrado de DataSet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('DS_Proyecto_01_Datos_Properati.csv')\n",
    "df = df[['rooms', 'bedrooms', 'bathrooms', 'surface_total', 'surface_covered', 'price', 'property_type','l2','l3']]\n",
    "ds_prop_filt = df.query('surface_total <= 180 & surface_covered<=surface_total & surface_covered>=30 & price <= 400000')\n",
    "print(ds_prop_filt.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Determinación de categorías de precios`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds_prop_filt.price.describe()) \n",
    "idx_array = np.array(ds_prop_filt.index)\n",
    "idx_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **`Utilizo:`**\n",
    "##### Precios/categorías:\n",
    "- `Bajos`: menores a 100000\n",
    "- `Medios` o normales: entre 100000 y 400000\n",
    "- `Altos` o elevados: mayores a 400000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precio_lista = []\n",
    "for i in idx_array:\n",
    "    value = int(ds_prop_filt.price[i])\n",
    "    if value < 100000:\n",
    "        precio_lista.append('bajo')\n",
    "    elif value < 220000:\n",
    "        precio_lista.append('medio')\n",
    "    else:\n",
    "        precio_lista.append('alto')\n",
    "array_precio = np.array(precio_lista)\n",
    "ds_prop_filt = ds_prop_filt.assign(precio = array_precio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataSet con columna de categorías de precios`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_prop_filt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown('## `Gráfico`'))\n",
    "display(Markdown('#### Evaluación de categorías por zonas:'))\n",
    "fig, ax = plt.subplots(figsize=(18,6))\n",
    "with sns.axes_style('whitegrid'):\n",
    "    sns.countplot(x = 'precio', hue = 'l2', data = ds_prop_filt, order = ['alto', 'medio', 'bajo'], palette = 'Set1', edgecolor = 'k')\n",
    "    plt.xlabel('Precios', fontdict = {'fontsize':14})\n",
    "    plt.ylabel('N° de instancias', fontdict = {'fontsize':14})\n",
    "    plt.title('Categorías de precios por zona', fontdict = {'fontsize':16})\n",
    "    plt.tick_params(labelsize = 'large', rotation = 45)\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de este gráfico puedo hacer las siguientes conclusiones:\n",
    "- En GBA Zona Norte y Capital Federal las categorías de precios se pueden rankear: `medios`, `altos` y `bajos`\n",
    "- En GBA Zona Oeste y GBA Zonas Sur las categorías de precios se pueden rankear: `bajos`, `medios`, y `altos`\n",
    "\n",
    "##### **De todos modos**, para poder comparar entre regiones y determinar cuál es la más cara, debo utilizar como comparador los porcentajes de las categorías dentro de cada región."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown('#### Evaluación de categorías de precios por zonas:'))\n",
    "array_vc = np.unique(ds_prop_filt['l2'].values)\n",
    "k = 1\n",
    "plt.figure(figsize = (18,10))\n",
    "for element in array_vc:\n",
    "    vc_l2 = pd.DataFrame(data = ds_prop_filt[ds_prop_filt['l2'] == element]['precio'].value_counts())\n",
    "    vc_l2 = vc_l2.rename(columns = {'precio':'Cantidad'})\n",
    "    vc_l2['porcentaje'] = round((vc_l2['Cantidad']/vc_l2['Cantidad'].sum())*100,2)\n",
    "    display(Markdown('Precios en: **'+element+'**'))\n",
    "    display(pd.DataFrame(vc_l2.porcentaje))\n",
    "    plt.subplot(2,2,k)\n",
    "    k += 1\n",
    "    sns.barplot(x = vc_l2.index, y = 'porcentaje', data = vc_l2, order = ['alto', 'medio', 'bajo'], palette = 'viridis', edgecolor = 'k')\n",
    "    plt.ylabel('Porcentaje [%]')\n",
    "    plt.xlabel('Categoría de precios')\n",
    "    plt.title('Zona: '+element)\n",
    "    plt.grid()\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las dos zonas más caras son entonces: `GBA Zona Norte `y `Capital Federal`.\n",
    "\n",
    "Si se tienen en cuenta categorías de precios medios y altos, `Capital Federal` sería la región menos económica.\n",
    "\n",
    "Se debe tener en cuenta que solamente se consideran las categorías de precios según rangos determinados por los cuantiles. Ahora evalúo dentro de esas dos zonas más caras la variable `price`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_prop_alto = ds_prop_filt.query('l2 in [\"Capital Federal\", \"Bs.As. G.B.A. Zona Norte\"]') \n",
    "ds_prop_alto.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown('### Distribución de la variable `price`:'))\n",
    "plt.figure(figsize=(18,10))\n",
    "plt.subplot(2,2,1)\n",
    "sns.distplot(ds_prop_alto[ds_prop_alto.l2 == 'Capital Federal']['price'], label = 'Capital Federal')\n",
    "sns.distplot(ds_prop_alto[ds_prop_alto.l2 == 'Bs.As. G.B.A. Zona Norte']['price'], label = 'GBA Zona Norte')\n",
    "plt.grid()\n",
    "plt.ylabel('Frecuencia', fontdict = {'fontsize':14})\n",
    "plt.xlabel('Precios en dólares', fontdict = {'fontsize':14})\n",
    "plt.title('Histograma', fontdict = {'fontsize':16})\n",
    "plt.legend()\n",
    "plt.subplot(2,2,2)\n",
    "sns.violinplot(x = 'l2', y = 'price', data = ds_prop_alto, palette = 'PuRd')\n",
    "plt.title('Violinplot', fontdict = {'fontsize':16})\n",
    "plt.xlabel('Zona', fontdict = {'fontsize':14})\n",
    "plt.ylabel('Precio', fontdict = {'fontsize':14})\n",
    "plt.subplot(2,2,3)\n",
    "sns.boxplot(x = 'l2', y = 'price', data = ds_prop_alto, palette = 'RdPu')\n",
    "plt.title('Boxplot', fontdict = {'fontsize':16})\n",
    "plt.xlabel('Zona', fontdict = {'fontsize':14})\n",
    "plt.ylabel('Precio', fontdict = {'fontsize':14})\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Se puede concluir que la variable precio no muestra una diferencia significativa en su distribución para las dos regiones más caras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Analizo si hay diferencia de precios y dimensiones de las superficies en los tipos de propiedades para las regiones más caras`\n",
    "\n",
    "**_Utilizo las tres clases más abundantes: `Departamento`, `PH` y `Casa`._**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_prop_alto = ds_prop_alto.query(\"property_type in ['Departamento', 'PH', 'Casa']\")\n",
    "ds_prop_alto.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown('##### Pairplot de variables: `price, surface_total, surface_covered`'))\n",
    "sns.pairplot(ds_prop_alto[['price','surface_total','surface_covered', 'property_type']], hue = 'property_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown('##### Boxplots variables: `price, surface_total, surface_covered`'))\n",
    "col = ['price', 'surface_total', 'surface_covered']\n",
    "k = 1\n",
    "plt.figure(figsize = (18,10))\n",
    "for i in col:\n",
    "    plt.subplot(2,2,k)\n",
    "    sns.boxplot(x = 'property_type', y = i, data = ds_prop_alto, palette = 'viridis')\n",
    "    plt.title('Boxplot', fontdict = {'fontsize': 16})\n",
    "    plt.xlabel('Tipo de propiedad', fontdict = {'fontsize': 14})\n",
    "    k += 1\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Conclusiones:\n",
    "- Variable `price`: la distribución no presenta diferencia significativa para los distintos tipos de propiedades\n",
    "- Variable `surface_total`: hay diferencia significativa para los distintos tipos de propiedades. El 75% de los valores de **Departamento** son menores a por lo menos el 75% de los valores de **Casa**, ya que se observa que el RIQ  de Departamentos está por debajo del cuantil 25% de Casa. La mediana de **Casa** se encuentra incluso por encima del RIQ de **PH**. Estas diferencias tienen su explicación en que los departamentos y PH's no suelen tener superficies no cubiertas o espacios al 'aire libre', como si sucede en la mayoría de las casas\n",
    "- Variable `surface_covered`: igual que para `surface_total` hay diferencia significativa para los tres tipos de propiedades\n",
    "\n",
    "\n",
    "##### **Por último**, voy a filtrar el DataSet de las zonas más caras sólo para Capital Federal y los tipos de propiedades más abundantes: `Departamento`. \n",
    "##### De esta forma el nuevo DataSet `'ds_prop_alto_dpto'` es comparable con el DataSet obtenido en EDA, con la diferencia que este DS. considera los tres tipos de propiedades más abundantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_prop_alto_dpto = ds_prop_alto.query(\" property_type == 'Departamento'\")\n",
    "ds_prop_alto_dpto.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_desafio = ds_prop_alto_dpto.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,8))\n",
    "plt.subplot(1,2,1)\n",
    "sns.heatmap(corr_desafio, cmap = 'viridis', annot = True, annot_kws = {'fontsize': 13}, square = True)\n",
    "plt.title('Mapa de calor: correlaciones desafío', fontdict = {'fontsize':18})\n",
    "plt.tick_params(size = 16, rotation = 45)\n",
    "plt.subplot(1,2,2)\n",
    "sns.heatmap(corr_eda, cmap = 'viridis', annot = True, annot_kws = {'fontsize': 13} , square = True) #Correlación EDA\n",
    "plt.title('Mapa de calor: correlaciones EDA', fontdict = {'fontsize':18})\n",
    "plt.tick_params(size = 16, rotation = 45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Conclusiones finales: \n",
    "\n",
    "- Del DataSet original las regiones más caras son Capital Federal y G.B.A. Zona Norte, con gran diferencia con las otras dos zonas. \n",
    "- Dentro de estas regiones se puede ver que hay diferencia en las variables de superficie cubierta y total para cada tipo de propiedad, por lo que sería necesario separarlas para poder estudiarlas. \n",
    "- No hay diferencia para los tipos de propiedades y la variable precio.\n",
    "- Separando los tipos de propiedades y evaluando las correlaciones para un DataSet con tipo de propiedad `Departamento` (dentro de Capital Federal) y comparándolas con las correlaciones obtenidas luego del análisis EDA (mismos filtros de variables price, surface_covered, surface_total, l2, excepto que contiene los 3 tipos de propiedades más abundantes) puedo ver que:\n",
    "    - aumenta en casi 12% la correlación entre variables `rooms`, `bedrooms`, `bathrooms` con `price`\n",
    "    - aumenta en casi 15% la correlación entre las variables `surface_total`, `surface_covered` con `price`\n",
    "    - el resto de las correlaciones permanecen similares o no se justifica comentar los cambios \n",
    "---\n",
    " ###  `|` Respuesta\n",
    "##### ***Sí hay diferentes tendencias en los precios de las zonas del Dataset*** , y dentro de las zonas más caras, ***se encuentran diferencias significativas entre algunas variables para los distintos tipos de propiedades más abundantes***, por lo que se sugiere separarlas para evaluarlas - al menos al tipo Departamento. Al considerar sólo este tipo de propiedad, ***se notan cambios en la medida de hasta un 15%*** en la correlación de las variables con la variable `price`, la cual nos interesará luego predecir. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Machine Learning\n",
    "\n",
    "En esta sección, debes entrenar dos modelos de Machine Learning - uno de vecinos más cercanos y otro de árboles de decisión -  para predecir el precio de las propiedades tipo `Departamento` en la Ciudad Autónoma de Buenos Aires (`Capital Federal`). Para ello, no debes olvidarte de:\n",
    "\n",
    "* Elegir una métrica apropiada para evaluar los resultados de los modelos.\n",
    "* Seleccionar las variables predictoras (`X`) y la variable a predecir (`y`). \n",
    "* Realizar un Train/Test split de los datos.\n",
    "* Generar un modelo *benchmark* y evaluarlo.\n",
    "* Entrenar un modelo de vecinos más cercanos y un modelo de árbol de decisión con hiperparámetros iniciales de su elección.\n",
    "* Evaluar los modelos obtenidos. Para ello, evalúa la métrica elegida en el conjunto de Test y en el conjunto de Train. También, realiza gráficos de valores reales vs. valores predichos.\n",
    "* Mejorar el desempeño de sus modelos optimizando el número de vecinos y la profundidad del árbol, respectivamente.\n",
    "* Entre los modelos entrenados, ¿cuál elegirías para utilizar?¿Por qué? \n",
    "* Ser **crítico/a** con la metodología utilizada. Por ejemplo, responde las siguientes preguntas: ¿Qué información no estás usando que podría ayudar al modelo?¿Qué información puede estar demás o repetida?\n",
    "\n",
    "**Importante:** para asegurarnos que trabajes con un dataset apropiados, debes volver a cargar los datos y realizar el siguiente filtrado:\n",
    "\n",
    "1. Selecciona aquellas propiedades en Capital Federal y cuyo tipo de propiedad es Departamento, PH o Casa.\n",
    "1. Selecciona aquellas propiedades cuya superficie total es menor a 1000 m2 y mayor a 15 m2.\n",
    "1. Selecciona aquellas propiedades cuya precio es menor 4000000 dólares.\n",
    "1. Selecciona las columnas `rooms`, `bedrooms`, `bathrooms`, `surface_total`, `surface_covered` y `price`.\n",
    "1. Descarta aquellas instacias con valores faltantes.\n",
    "\n",
    "**Checkpoint:** deberías obtener un dataset con 81019 instacias y 6 columnas."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Métrica para evaluar los resultados: R2 Score. \n",
    "\n",
    "Elegí ***r2_score*** porque es una medida estadística de qué tan bien las predicciones de regresión se aproximan a los puntos de datos reales\n",
    "- El mejor puntaje posible es 1.0 - indica que las predicciones se ajustan perfectamente a los datos -, y puede ser negativo (porque el modelo puede ser arbitrariamente peor). \n",
    "- Un modelo constante que siempre predice el valor esperado de y, sin tener en cuenta las características de entrada, obtendría una puntuación R² de 0.0 - `caso que se verá en el modelo de Benchmark `.\n",
    "\n",
    "##### R2 se puede definir como una versión normalizada o reescalada del MSE. \n",
    "  - Si MSE = 0, entonces R2 = 1.0: las predicciones son perfectas\n",
    "  - Si MSE es tan malo como simplemente adivinar la media de todo, entonces R2 = 0.0, tan malo como sea posible\n",
    "  \n",
    "##### Es más intuitivo utilizar r2_score que MSE, y el fin es el mismo, reducir el error cuadrático medio y asegurar que las predicciones sean buenas. Por eso decidí utilizar r2_score. \n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "\n",
    "###### ***Nota***: voy a medir también RMSE, MAE y Max Error como medidas auxiliares para evaluar los distintos modelos, cuando r2_score sea similar. \n",
    "\n",
    "---\n",
    "\n",
    "#### Definición de variables\n",
    "\n",
    "##### Variable a predecir (y): `price`\n",
    "\n",
    "##### Variables predictoras (X): `rooms`, `bathrooms`, `surface_covered`\n",
    "\n",
    "- No utilizo:  `bedrooms` ya que está altamente correlacionada con `rooms`, está considerada dentro de `rooms` (es un tipo de habitación), y porque esta última tiene más sentido usarla.\n",
    "- No utilizo: `surface_total` para la predicción de Departamentos, ya que, como se concluyó en el desafío, hay mucha diferencia para los tipos Casa, PH y departamento, y por otro lado está altamente correlacionada con `surface_covered`, que si me interesa utilizar y tiene más sentido. \n",
    "---\n",
    "#### Benchmark\n",
    "\n",
    "- Como modelo para Benchmark elegí uno que para cualquier valor a predecir dé como resultado el valor esperado o valor medio de la variable de salida. Es un modelo muy simple y muy malo para predecir. \n",
    "\n",
    "###### El modelo será evaluado a continuación. \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de librerías\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "# Carga de datos\n",
    "ds_prop = pd.read_csv('DS_Proyecto_01_Datos_Properati.csv') \n",
    "ds_prop = ds_prop.query(\" l2 =='Capital Federal' & property_type in ['Departamento', 'PH', 'Casa']\")\n",
    "ds_prop = ds_prop[['rooms', 'bedrooms','bathrooms', 'surface_total', 'surface_covered', 'price']] \n",
    "ds_prop = ds_prop.query(\"surface_total>=15 & surface_total<=1000 & price<=4000000\") \n",
    "ds_prop.dropna(inplace=True)\n",
    "ds_prop.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Clase RegressionModels:\n",
    "\n",
    "- Se debe ingresar DataSet, variable a predecir y variables predictoras (si éstas últimas no se ingresan, la clase utiliza todas las features restantes de tipo float64 o int64 del DataSet).\n",
    "\n",
    "##### Cuando se inicia la clase las variables `X` e `y` se dividen en dos conjuntos de train y test, que quedarán disponibles para las predicciones y evaluaciones. \n",
    "\n",
    "#### Dentro de la clase están definidas las siguientes funciones: \n",
    "\n",
    "##### •`RegressionModels_tree`, `RegressionModels_knn`, `RegressionModels_linear`: entrenan modelos y hacen predicciones de árboles de decisión, vecinos cercanos y regresión lineal respectivamente\n",
    "##### •`RegressionModels_plot_metrics` : devuelve las métricas de ***rs_score, mean absolute error, root mean squared error y max error*** en tablas y gráficos\n",
    "##### •`RegressionModels_plot_errors`: grafica las diferencias entre las predicciones y los valores reales en histogramas y boxplots\n",
    "##### •`RegressionModels_plot_predictions`: grafica en histogramas las variables de Train y Test predecidas, y un scatter de las variable Test predecida vs real\n",
    "##### •Otras funciones: `Benchmark`, `plot_traintest`\n",
    "##### •`run_all`: corre todas las funciones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionModels:\n",
    "    def __init__(self, dataset, y_column_name, x_columns = 0):\n",
    "        \"\"\"\n",
    "       \n",
    "        La clase eliminará toda columna del dataset que no sea tipo float64 o int64\n",
    "        \n",
    "        Variable de respuesta: y_column_name (string). Ingresar como: 'y_column_name'\n",
    "        \n",
    "        Variables independientes: 'x_columns', si no se modifica, toma todas las columnas del dataset \n",
    "        \n",
    "        En caso de ingresar 'x_columns' debe tener la siguiente sintaxis: ['column_name_1', 'column_name_2', ...]\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        # Definición de variables\n",
    "        self.dataset = dataset.select_dtypes(include = ['float64','int64']) # Dejo únicamente las columnas con las que puedo trabajar\n",
    "        self.y_ds = self.dataset.loc[:, y_column_name]\n",
    "                \n",
    "\n",
    "        if x_columns != 0:\n",
    "            self.x_ds = self.dataset.loc[:,x_columns]\n",
    "        else:\n",
    "            self.x_ds = self.dataset.loc[:,:]\n",
    "            self.x_ds.drop(y_column_name, axis = 1, inplace = True)\n",
    "             \n",
    "        self.y_pred = {}\n",
    "        self.y_pred_train = {}\n",
    "        self.tree_range = []\n",
    "        self.knn_n = []\n",
    "        self.tree_model = False\n",
    "        self.knn_model = False\n",
    "        self.linear_model = False\n",
    "        self.y_column_name = y_column_name\n",
    "        self.x_columns = x_columns\n",
    "        \n",
    "        # Definición de variables de Train y Test\n",
    "        self.y_ds = pd.Series(self.y_ds)\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        X = np.array(self.x_ds)\n",
    "        y = np.array(self.y_ds)\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "   \n",
    "        from IPython.display import display, Markdown\n",
    "        display(Markdown(\"\"\"---\n",
    "# **RegressionModels** `Class`\"\"\"))\n",
    "        display(Markdown(\"\"\"\n",
    "##### Ha ingresado un dataset con \"\"\"+str(self.x_ds.shape[0])+\"\"\" instancias y \"\"\"+str(dataset.shape[1])+\"\"\" columnas.\n",
    "##### La variable a predecir, y, es la siguiente: ***\"\"\"+self.y_column_name+\"\"\"***\n",
    "##### Las variables predictoras, X, son las siguientes: ***\"\"\" +str(self.x_ds.columns.values)+\"\"\"***\n",
    "###### Se ha separado el dataset en uno de train (70%) y otro de test (30%). Las predicciones se harán sobre estos datasets. \"\"\"))\n",
    "        display(Markdown(\"\"\"---\n",
    "#### Las funciones disponibles son las siguientes:\"\"\"))\n",
    "        display(Markdown(\"\"\"\n",
    "##### •`run_all`: corre todas las funciones \n",
    "##### •`RegressionModels_tree`, `RegressionModels_knn`, `RegressionModels_linear`: entrenan modelos y hacen predicciones\n",
    "##### •`RegressionModels_plot_metrics` : devuelve las métricas de errores en tablas y gráficos\n",
    "##### •`RegressionModels_plot_errors`: grafica las diferencias entre las predicciones y los valores reales\n",
    "##### •`RegressionModels_plot_predictions`: grafica en histogramas las variables de Train y Test predecidas\n",
    "##### •Otras funciones: `Benchmark`, `plot_traintest`\n",
    "\"\"\"))\n",
    "        self.plot_traintest()\n",
    "        \n",
    "            # Fin __init__  \n",
    "    def plot_traintest(self):\n",
    "        from IPython.display import display, Markdown\n",
    "        display(Markdown(\"\"\"---\n",
    "##### Se ha separado el dataset en uno de Train (70%) y otro de Test (30%)\n",
    "\n",
    "#### Gráficos distribución Y, Y Train, Y Test\n",
    "\"\"\"))\n",
    "        with sns.axes_style('whitegrid'):\n",
    "            ytt_list = [self.y_ds, self.y_train, self.y_test]\n",
    "            ytt_names = [' ', 'Train', 'Test']\n",
    "            i = 1\n",
    "            plt.figure(figsize=(18,9))\n",
    "            for p in range(0,3):\n",
    "                plt.subplot(3,2,i)\n",
    "                sns.distplot(ytt_list[p], bins = 30, kde = False, hist_kws = {'edgecolor': 'k'})\n",
    "                plt.title('Histograma Variable Y '+ytt_names[p], fontdict = {'fontsize':16})\n",
    "                plt.xlabel('Variable Y '+ytt_names[p], {'fontsize': 14})\n",
    "                plt.xlim(0)\n",
    "                plt.xticks(rotation = 45)\n",
    "                i += 1\n",
    "                plt.subplot(3,2,i)\n",
    "                sns.violinplot(ytt_list[p])\n",
    "                plt.title('Violinplot Variable Y '+ytt_names[p], fontdict = {'fontsize':16})\n",
    "                plt.xlabel('Variable Y '+ytt_names[p], {'fontsize': 14})\n",
    "                plt.xlim(0)\n",
    "                plt.xticks(rotation = 45)\n",
    "                i += 1\n",
    "          \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    " \n",
    "\n",
    "    def Benchmark(self):\n",
    "        from sklearn.metrics import mean_squared_error, r2_score\n",
    "        from IPython.display import display, Markdown\n",
    "        display(Markdown(\"\"\"---\n",
    "## `Benchmark`:\n",
    "#### El modelo predice siempre el valor medio\"\"\"))\n",
    "        self.y_pred = {} #En caso que ya tenga valores cargados de antes.. \n",
    "        self.y_pred_train = {}\n",
    "        \n",
    "        prediction = self.y_train.sum()/self.y_train.shape[0]\n",
    "        \n",
    "        self.y_pred['benchmark_Test'] = np.ones(self.X_test.shape[0])*prediction\n",
    "        self.y_pred_train['benchmark_Train'] = np.ones(self.X_train.shape[0])*prediction\n",
    "        \n",
    "        self.y_pred = pd.DataFrame(self.y_pred)\n",
    "        self.y_pred_train = pd.DataFrame(self.y_pred_train)\n",
    "        \n",
    "        self.y_pred = np.array(self.y_pred)\n",
    "        self.y_pred_train = np.array(self.y_pred_train)\n",
    "        \n",
    "\n",
    "        plt.figure(figsize=(18,5))\n",
    "        sns.scatterplot(self.y_test, self.y_pred[:,0])\n",
    "        plt.title('Valores reales vs valores predecidos')\n",
    "        plt.xlabel('Y Test')\n",
    "        plt.ylabel('Y Pred')\n",
    "        plt.xticks(rotation = 45)\n",
    "        plt.yticks(rotation = 45)\n",
    "        r2_score_ = []\n",
    "        rmse_ = []\n",
    "        r2_score_train = []\n",
    "        rmse_train = []\n",
    "        \n",
    "        rmse_.append((np.sqrt(mean_squared_error(y_true = self.y_test, y_pred = self.y_pred[:,0]))))\n",
    "        r2_score_.append((r2_score(y_true = self.y_test, y_pred = self.y_pred[:,0])))\n",
    "        \n",
    "        rmse_train.append((np.sqrt(mean_squared_error(y_true = self.y_train, y_pred = self.y_pred_train[:,0]))))\n",
    "        r2_score_train.append((r2_score(y_true = self.y_train, y_pred = self.y_pred_train[:,0])))\n",
    "        \n",
    "        self.y_pred = pd.DataFrame(self.y_pred)\n",
    "        self.y_pred_train = pd.DataFrame(self.y_pred_train)\n",
    "        \n",
    "        metrics_test = {'R2 Score Y Test':r2_score_, 'RMSE Y Test':rmse_}\n",
    "        metrics_train = {'R2 Score Y Train':r2_score_train, 'RMSE Y Train':rmse_train}\n",
    "        metrics = pd.DataFrame(metrics_test)\n",
    "        metrics2 = pd.DataFrame(metrics_train)                          \n",
    "                \n",
    "  #Plot del dataframe de las métricas\n",
    "        for i in range(0,2):\n",
    "            if i == 0:\n",
    "                k = metrics\n",
    "            else:\n",
    "                k = metrics2\n",
    "            fig, ax = plt.subplots()\n",
    "            fig.patch.set_visible(False)\n",
    "            the_table = ax.table(cellText=k.values, colLabels=k.columns, loc='center')\n",
    "            the_table.auto_set_font_size(False)\n",
    "            the_table.set_fontsize(20)\n",
    "            the_table.scale(5,3)\n",
    "\n",
    "            ax.axis('off')\n",
    "            ax.axis('tight')\n",
    "            plt.show()     \n",
    "        \n",
    "    \n",
    "    def RegressionModels_tree(self, min_depth = 1, max_depth = 5, random_state = 42):\n",
    "        \"\"\"\n",
    "        Ejecuta árboles de decisión para modelos de regresión.\n",
    "        \n",
    "        Devuelve dos DataFrames:\n",
    "            - DataFrame de la predicción sobre X_test\n",
    "            - DataFrame de la predicción sobre X_train\n",
    "        \"\"\"\n",
    "        self.y_pred = {} #En caso que ya tenga valores cargados de antes.. \n",
    "        self.y_pred_train = {}\n",
    "        if min_depth > max_depth:\n",
    "            max_depth = min_depth\n",
    "        self.tree_range = np.arange(min_depth, max_depth + 1, dtype=int)\n",
    "        self.knn_n = [] # Vacío la lista para que no interfiera en la función RegressionModels_plot_error(), sino tengo que agregarle a la función un atributo extra y una instancia de verficación\n",
    "        self.tree_model = True\n",
    "        self.knn_model = False\n",
    "        self.linear_model = False\n",
    "        from sklearn.tree import DecisionTreeRegressor\n",
    "        \n",
    "        for depth in range(min_depth, max_depth+1):\n",
    "            tree_regressor = DecisionTreeRegressor(max_depth = depth, random_state = random_state)\n",
    "            tree_regressor.fit(self.X_train, self.y_train)\n",
    "            depth = 'y_pred_depth_'+str(depth)\n",
    "            self.y_pred[depth] = tree_regressor.predict(self.X_test)\n",
    "            self.y_pred_train[depth] = tree_regressor.predict(self.X_train)\n",
    "       \n",
    "        self.y_pred = pd.DataFrame(self.y_pred)\n",
    "        self.y_pred_train = pd.DataFrame(self.y_pred_train)\n",
    "        \n",
    "        return self.y_pred\n",
    "    \n",
    "    \n",
    "    def RegressionModels_knn(self, n_knn_min = 3, n_knn_max = 5, nro_modelos = 3):\n",
    "        \"\"\"\n",
    "        Ejecuta KNN para modelos de regresión.\n",
    "        \n",
    "        Devuelve dos DataFrames:\n",
    "            - DataFrame de la predicción sobre X_test\n",
    "            - DataFrame de la predicción sobre X_train\n",
    "            \n",
    "        \"\"\"\n",
    "        self.y_pred = {} #En caso que ya tenga valores cargados de antes.. \n",
    "        self.y_pred_train = {}\n",
    "        if n_knn_min >= n_knn_max:\n",
    "            n_knn_max = n_knn_min\n",
    "            nro_modelos = 1\n",
    "        if n_knn_max > self.X_train.shape[0]: #Chequeo que el valor de vecinos elegido no supere la cantidad de datos disponibles para el entrenamiento\n",
    "            n_knn_max = self.X_train.shape[0]\n",
    "            \n",
    "        step = np.linspace(start= n_knn_min, stop=n_knn_max, num=nro_modelos, dtype=int) # Número de vecinos que va a tomar\n",
    "        step = np.unique(step) # Me aseguro que no hayan quedado valores repetidos\n",
    "        self.knn_n = step\n",
    "        self.tree_range = [] # Vacío la lista para que no interfiera en la función RegressionModels_plot_error(), sino tengo que agregarle a la función un atributo extra y una instancia de verficación\n",
    "        self.tree_model = False\n",
    "        self.knn_model = True\n",
    "        self.linear_model = False\n",
    "        from sklearn.neighbors import KNeighborsRegressor\n",
    "        \n",
    "        for k in range(0, step.size):\n",
    "            knn_regressor = KNeighborsRegressor(n_neighbors = step[k])\n",
    "            knn_regressor.fit(self.X_train, self.y_train)\n",
    "            step_str = str('KNeighbors_'+str(step[k]))\n",
    "            self.y_pred[step_str] = knn_regressor.predict(self.X_test)\n",
    "            self.y_pred_train[step_str] = knn_regressor.predict(self.X_train)\n",
    "         \n",
    "        self.y_pred = pd.DataFrame(self.y_pred)\n",
    "        self.y_pred_train = pd.DataFrame(self.y_pred_train)\n",
    "        \n",
    "        return self.y_pred\n",
    "    \n",
    "    \n",
    "    def RegressionModels_linear(self):\n",
    "        \"\"\"\n",
    "        Ejecuta el modelo de regresión lineal.\n",
    "        \n",
    "        Devuelve dos DataFrames:\n",
    "            - DataFrame de la predicción sobre X_test\n",
    "            - DataFrame de la predicción sobre X_train\n",
    "        \"\"\"\n",
    "        self.y_pred = {} #En caso que ya tenga valores cargados de antes.. \n",
    "        self.y_pred_train = {}\n",
    "        self.tree_range = [] \n",
    "        self.knn_n = []\n",
    "        self.tree_model = False\n",
    "        self.knn_model = False\n",
    "        self.linear_model = True\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        \n",
    "        linear_reg = LinearRegression()\n",
    "        linear_reg.fit(self.X_train, self.y_train)\n",
    "        self.y_pred['linear_regression'] = linear_reg.predict(self.X_test)\n",
    "        self.y_pred_train['linear_regression'] = linear_reg.predict(self.X_train)\n",
    "        \n",
    "        self.y_pred = pd.DataFrame(self.y_pred)\n",
    "        self.y_pred_train = pd.DataFrame(self.y_pred_train)\n",
    "        \n",
    "        return self.y_pred\n",
    "\n",
    "    def RegressionModels_plot_metrics(self): \n",
    "        \"\"\"\n",
    "        La función calcula y grafica las métricas de R2 score, max error, mean absolute error y root mean squared error.\n",
    "                \n",
    "        \"\"\"\n",
    "        from IPython.display import display, Markdown\n",
    "        from sklearn.metrics import r2_score, max_error, mean_absolute_error, mean_squared_error\n",
    "        r2_score_ = []\n",
    "        mae_ = []\n",
    "        rmse_ = []\n",
    "        max_error_ = []\n",
    "        r2_score_train = []\n",
    "        mae_train = []\n",
    "        rmse_train = []\n",
    "        max_error_train = []\n",
    "        Y_pred = np.array(self.y_pred) \n",
    "        Y_pred_train = np.array(self.y_pred_train)\n",
    "        model_type = []\n",
    "        \n",
    "        if self.tree_model == True:\n",
    "            x_range = self.tree_range\n",
    "            x_label = 'Profundidad del árbol'\n",
    "            modelo = 'Árboles de Decisión'\n",
    "            for t in range(0,Y_pred.shape[1]):\n",
    "                model_type.append('Depth: '+str(self.tree_range[t]))\n",
    "                \n",
    "        elif self.knn_model == True:\n",
    "            x_range = self.knn_n\n",
    "            x_label = 'Número de vecinos'\n",
    "            modelo = 'K Vecinos Cercanos'\n",
    "            for t in range(0,Y_pred.shape[1]):\n",
    "                model_type.append('KN: '+str(self.knn_n[t]))\n",
    "        elif self.linear_model == True:\n",
    "            x_range = np.arange(0,Y_pred.shape[1])  \n",
    "            x_label = ' '\n",
    "            modelo = 'Regresión Linear'\n",
    "            model_type.append('Regresión Linear')\n",
    "\n",
    "        for i in range(0, Y_pred.shape[1]):\n",
    "            r2_score_.append(round(r2_score(y_true = self.y_test, y_pred = Y_pred[:,i]),2))\n",
    "            mae_.append(int(mean_absolute_error(y_true = self.y_test, y_pred = Y_pred[:,i])))\n",
    "            max_error_.append(int(max_error(y_true = self.y_test, y_pred = Y_pred[:,i])))\n",
    "            rmse_.append(int(np.sqrt(mean_squared_error(y_true = self.y_test, y_pred = Y_pred[:,i]))))\n",
    "        for i in range(0, Y_pred_train.shape[1]):\n",
    "            r2_score_train.append(round(r2_score(y_true = self.y_train, y_pred = Y_pred_train[:,i]),2))\n",
    "            mae_train.append(int(mean_absolute_error(y_true = self.y_train, y_pred = Y_pred_train[:,i])))\n",
    "            max_error_train.append(int(max_error(y_true = self.y_train, y_pred = Y_pred_train[:,i])))\n",
    "            rmse_train.append(int(np.sqrt(mean_squared_error(y_true = self.y_train, y_pred = Y_pred_train[:,i]))))\n",
    "            \n",
    "        metrics_test = {'Modelo': model_type,'R2 Score Y Test':r2_score_, 'MAE Y Test':mae_, 'Max Error Y Test': max_error_, 'RMSE Y Test':rmse_}\n",
    "        metrics_train = {'Modelo': model_type, 'R2 Score Y Train':r2_score_train, 'MAE Y Train':mae_train, 'Max Error Y Train': max_error_train, 'RMSE Y Train':rmse_train}\n",
    "        metrics = pd.DataFrame(metrics_test)\n",
    "        metrics2 = pd.DataFrame(metrics_train)                          \n",
    "          \n",
    "\n",
    "        display(Markdown(\"\"\"---\n",
    "# Tabla y gráficos de las métricas de error:\n",
    "#### Modelo utilizado: \"\"\"+\"***\"+modelo+\"\"\"***\n",
    "\n",
    "##### Métricas utilizadas: R2_score, Mean Absolute Error, Root Mean Squared Error, Max Error.\n",
    "\n",
    "##### Tabla de métricas:\"\"\"))\n",
    "             \n",
    "        #Plot tabla métricas\n",
    "        for i in range(0,2):\n",
    "            if i == 0:\n",
    "                k = metrics\n",
    "            else:\n",
    "                k = metrics2\n",
    "            fig, ax = plt.subplots()\n",
    "            fig.patch.set_visible(False)\n",
    "            the_table = ax.table(cellText=k.values, colLabels=k.columns, loc='center')\n",
    "            the_table.auto_set_font_size(True)\n",
    "            the_table.scale(3,2)\n",
    "\n",
    "            ax.axis('off')\n",
    "            ax.axis('tight')\n",
    "            fig.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "         #Plot gráficas de las métricas  \n",
    "        plt.figure(figsize=(18,16))\n",
    "        with sns.axes_style('whitegrid'):\n",
    "            metrics_names =['R2 Score', 'RMSE',  'MAE', 'Max Error']\n",
    "            metrics_an = [r2_score_, r2_score_train, rmse_, rmse_train, mae_, mae_train, max_error_, max_error_train]\n",
    "            q = 0\n",
    "            for i in range(1,5):\n",
    "                p = i - 1\n",
    "                plt.subplot(4,1,i)\n",
    "                plt.title(metrics_names[p] +' Metric', {'fontsize':20})\n",
    "                plt.plot(x_range, np.array(metrics_an[q]), \"*-\", label = 'Test')\n",
    "                q += 1\n",
    "                plt.plot(x_range, np.array(metrics_an[q]), 'o-', label = 'Train')\n",
    "                q += 1\n",
    "                plt.legend()\n",
    "                plt.xlabel(x_label, {'fontsize':14})\n",
    "                plt.ylabel(metrics_names[p], {'fontsize':14})\n",
    "    \n",
    "\n",
    "            plt.subplots_adjust(hspace = 2.5)\n",
    "            plt.tight_layout() \n",
    "            plt.show() \n",
    "   \n",
    "   \n",
    "                  \n",
    "    def RegressionModels_plot_error(self, depth_or_knn = 0):\n",
    "        \"\"\"    \n",
    "        La función grafica el histograma de errores de las predicciones sobre X Train y X Test.\n",
    "        \n",
    "        También grafica un scatter para Y Test vs. Y pred.\n",
    "        \n",
    "                \n",
    "        Si se quiere graficar sólo una profundidad de árbol o n° de vecinos se debe indicar:\n",
    "            \n",
    "            - profundidad o n° de vecinos en el atributo 'depth_or_knn'\n",
    "        \n",
    "        \"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "        import seaborn as sns\n",
    "        import scipy.stats as stats\n",
    "        from IPython.display import display, Markdown\n",
    "        sns.set()\n",
    "        \n",
    "        def plotear(self):\n",
    "                plt.figure(figsize=(18,8))\n",
    "                plt.suptitle('Error Plots', fontsize = 26, ha = 'center', va = 'top')\n",
    "                with sns.axes_style('whitegrid'):    \n",
    "\n",
    "                    plt.subplot(1,1,1)\n",
    "                    sns.distplot(y_pred_array - self.y_test, bins = 20, label = 'Test')\n",
    "                    sns.distplot(y_pred_train_array - self.y_train, bins = 20, label = 'Train')\n",
    "                    plt.legend()\n",
    "                    plt.xlabel('Error', {'fontsize':14})\n",
    "\n",
    "            \n",
    "                    plt.subplots_adjust(wspace = 1.5, hspace = 2.5)\n",
    "                    plt.show() \n",
    "        \n",
    "        # Si cargo valores entonces entra en esta IF CLAUSE:\n",
    "        if depth_or_knn != 0: \n",
    "            if depth_or_knn in self.tree_range or depth_or_knn in self.knn_n: # Si el modelo fuera lineal no entra en este if\n",
    "                if self.tree_model == True: \n",
    "                    idx = str('y_pred_depth_'+str(depth_or_knn))\n",
    "                    y_pred_array = np.array(self.y_pred[idx])\n",
    "                    y_pred_train_array = np.array(self.y_pred_train[idx])\n",
    "                    plotear(self)\n",
    "                else: # Implica que es un modelo de knn\n",
    "                    idx = str('KNeighbors_'+str(depth_or_knn))\n",
    "                    y_pred_array = np.array(self.y_pred[idx])\n",
    "                    y_pred_train_array = np.array(self.y_pred_train[idx])\n",
    "                    plotear(self)\n",
    "            else: \n",
    "                    display(Markdown('El valor ingresado no es correcto. Si el modelo utilizado es el lineal, no debe ingresar ningún valor.'))\n",
    "        # Si no se ingresaron valores, grafica para todas las predicciones realizadas\n",
    "        else: \n",
    "                if self.tree_model == True:\n",
    "                    modelo = 'Árboles de Decisión'\n",
    "                elif self.knn_model == True:\n",
    "                    modelo = 'K Vecinos Cercanos'\n",
    "                elif self.linear_model == True:\n",
    "                    modelo = 'Regresión Lineal'\n",
    "                    \n",
    "                display(Markdown(\"\"\"---\n",
    "# Gráficos de las diferencias entre predicciones y los valores reales:\n",
    "#### Modelo utilizado: \"\"\"+\"***\"+modelo+\"***\"))\n",
    "                \n",
    "                n_pred = self.y_pred.shape[1]\n",
    "                \n",
    "                plt.figure(figsize=(30,8*n_pred))\n",
    "                k = 1\n",
    "                sns.set_palette('Set1')\n",
    "       \n",
    "                with sns.axes_style('whitegrid'):\n",
    "            \n",
    "                    for i in range(0, n_pred): \n",
    "                        \n",
    "                        data = np.array(self.y_pred[self.y_pred.columns[i]] - self.y_test)\n",
    "                        x_min = np.quantile(a = data, q = 0.05)\n",
    "                        x_max = np.quantile(a = data, q = 0.95)\n",
    "                        \n",
    "                        plt.subplot(n_pred,2,k)\n",
    "                        sns.distplot(data, bins = 50, label = 'Y Test', kde = False, hist_kws = {'edgecolor':'k'})\n",
    "                        sns.distplot(self.y_pred_train[self.y_pred_train.columns[i]] - self.y_train, bins = 50, label = 'Train', kde = False, hist_kws = {'edgecolor':'k'})\n",
    "                        plt.legend()\n",
    "                        plt.xlabel('Error', {'fontsize':16})\n",
    "                        plt.title('Histograma - Diferencia entre Y & Y predicted - '+self.y_pred_train.columns[i], {'fontsize':20})\n",
    "                        plt.tick_params(labelsize = 16, rotation = 45)\n",
    "                        k += 1\n",
    "                        \n",
    "                        plt.subplot(n_pred,2,k)\n",
    "                        sns.boxplot(data)\n",
    "                        plt.xlabel('Error', {'fontsize':16})\n",
    "                        plt.xlim(x_min,x_max)\n",
    "                        plt.title('Boxplot - Diferencia entre Y test & Y test predicted - ' +self.y_pred_train.columns[i], {'fontsize':20})\n",
    "                        plt.tick_params(labelsize = 16, rotation = 45)\n",
    "                        k += 1\n",
    "\n",
    "                                    \n",
    "                    plt.subplots_adjust(wspace = 2.5, hspace = 2.5)\n",
    "                    plt.tight_layout()\n",
    "                    plt.show()     \n",
    "                    \n",
    "                    \n",
    "\n",
    "\n",
    "    def RegressionModels_plot_predictions(self):\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        from IPython.display import display, Markdown\n",
    "        n_pred = self.y_pred.shape[1]\n",
    "        if self.tree_model == True:\n",
    "            modelo = 'Árboles de Decisión'\n",
    "        elif self.knn_model == True:\n",
    "            modelo = 'K Vecinos Cercanos'\n",
    "        else:\n",
    "            modelo = 'Regresión Lineal'\n",
    "        display(Markdown(\"\"\"---\n",
    "# Gráficos de las predicciones:\n",
    "#### Histogramas y Scatterplots\n",
    "#### Modelo utilizado: \"\"\"+\"***\"+modelo+\"\"\"***\n",
    "\"\"\"))\n",
    "                \n",
    "        fig = plt.figure(figsize=(30,8*(n_pred+1)))\n",
    "        \n",
    "        k = 1\n",
    "        sns.set_palette('Set1')\n",
    "       \n",
    "        with sns.axes_style('whitegrid'):\n",
    "            \n",
    "            for i in range(0, n_pred): #Columna 0 del dataset y_pred\n",
    "\n",
    "                plt.subplot(n_pred+1, 2, k) #Primera fila del subplot = 0 + 1 = 1 \n",
    "                sns.distplot(self.y_pred[self.y_pred.columns[i]], kde = False, bins = 100, hist_kws = {'edgecolor':'k'})\n",
    "                plt.title('Histogram -'+self.y_pred.columns[i] , {'fontsize':20})\n",
    "                plt.xlabel('Predicted value: '+self.y_column_name, {'fontsize':18})\n",
    "                plt.tick_params(labelsize = 16, rotation = 45)\n",
    "                k += 1\n",
    "\n",
    "\n",
    "                ax = plt.subplot(n_pred+1,2,k)\n",
    "                sns.scatterplot(self.y_test, self.y_pred[self.y_pred.columns[i]])\n",
    "                lims = [np.min([ax.get_xlim(), ax.get_ylim()]),  np.max([ax.get_xlim(), ax.get_ylim()]), ]\n",
    "                ax.plot(lims, lims, 'k-', alpha=0.75, zorder = 0)\n",
    "                plt.xlabel('Y Test', {'fontsize':16})\n",
    "                plt.ylabel(self.y_pred.columns[i], {'fontsize':16})\n",
    "                plt.title('Scatterplot - Y test vs Y test predicted', {'fontsize':20})\n",
    "                plt.tick_params(labelsize = 16, rotation = 45)\n",
    "                k += 1               \n",
    "\n",
    "\n",
    "            plt.subplot(n_pred+1, 2, k)\n",
    "            sns.distplot(self.y_test, kde = False, bins = 100, hist_kws = {\"edgecolor\":\"k\"})\n",
    "            plt.title('Histogram Y Test', {'fontsize':20})\n",
    "            plt.xlabel(self.y_column_name, {'fontsize':18})\n",
    "            plt.tick_params(labelsize = 16, rotation = 45)\n",
    "            k += 1\n",
    "            \n",
    "\n",
    "            plt.subplots_adjust(wspace = 2.5, hspace = 2.5)\n",
    "            plt.tight_layout(rect = [0, 0, 0.97, 0.97] )\n",
    "            plt.show()\n",
    "            \n",
    "    def run_all(self, a = 3, b = 5, c = 3, model = 'tree'):\n",
    "        \"\"\"\n",
    "        Devuelve predicciones, plots de métricas, errores y distribuciones.\n",
    "        \n",
    "        **Por defecto** realiza tres predicciones de árboles de decisión con profundidades 3, 4 y 5, y random_state = 42. (model = 'tree')\n",
    "        \n",
    "        \n",
    "        *Para modificar los atributos:*\n",
    "        \n",
    "        Decision Tree: \n",
    "                        - model = 'tree'\n",
    "                        - a = min_depth (interger)\n",
    "                        - b = max_depth (interger)\n",
    "                        - c = random_state (interger - por defecto la función coloca 42)\n",
    "        \n",
    "        KNN:\n",
    "                        - model = 'knn'\n",
    "                        - a = k_neighbors_min (interger)\n",
    "                        - b = k_neighbors_max (interger)\n",
    "                        - c = nro_modelos (interger - por defecto es 3)\n",
    "        \n",
    "        Linear Regression:\n",
    "                        - model = 'linear'\n",
    "        \n",
    "        \"\"\"\n",
    "        from IPython.display import display, Markdown \n",
    "        display(Markdown(\"\"\"---\n",
    "# **RegressionModels** `\"\"\"+str(model) +\"\"\"`\"\"\"))\n",
    "        display(Markdown(\"\"\"\n",
    "##### La variable a predecir, y, es la siguiente: ***\"\"\"+self.y_column_name+\"\"\"***\n",
    "##### Las variables predictoras, X, son las siguientes: ***\"\"\" +str(self.x_ds.columns.values)+\"***\"))\n",
    "        \n",
    "       \n",
    "        if model == 'tree':\n",
    "            if c == 3:\n",
    "                c = 42 # Modifico el random_state si no recibo uno diferente\n",
    "                display(Markdown(\"\"\"---\n",
    "\n",
    "### `Se ha entrenado un árbol de decisión con profundidad de: \"\"\"+str(a)+\" a \"+str(b)+\"`\"))\n",
    "            self.RegressionModels_tree(min_depth = a, max_depth = b, random_state = c)\n",
    "            self.RegressionModels_plot_metrics() \n",
    "            self.RegressionModels_plot_error()\n",
    "            self.RegressionModels_plot_predictions()\n",
    "        elif model == 'knn':\n",
    "            self.RegressionModels_knn(n_knn_min = a, n_knn_max = b, nro_modelos = c)\n",
    "            display(Markdown(\"\"\"---\n",
    "\n",
    "### `Se ha entrenado un modelo de vecinos cercanos con k: \"\"\"+str(self.knn_n)+\"`\"))\n",
    "            self.RegressionModels_plot_metrics()\n",
    "            self.RegressionModels_plot_error()\n",
    "            self.RegressionModels_plot_predictions()\n",
    "        elif model == 'linear':\n",
    "            display(Markdown(\"\"\"---\n",
    "\n",
    "### `Se ha entrenado un modelo de regresión lineal`\"\"\"))\n",
    "            self.RegressionModels_linear()\n",
    "            self.RegressionModels_plot_metrics()\n",
    "            self.RegressionModels_plot_error()\n",
    "            self.RegressionModels_plot_predictions()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicio la clase con el dataset, las variables predictoras: 'rooms', 'bathrooms' y 'surface_covered', y la variable a predecir: 'price'\n",
    "model = RegressionModels(ds_prop, 'price', ['rooms','bathrooms','surface_covered'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pruebo el modelo de Benchmark\n",
    "model.Benchmark()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### El modelo utilizado para Benchmark es un modelo muy simple y no es un buen predictor, ya que cualquiera sean los valores ingresados en las variables predictoras, la varible a predecir tomará siempre el mismo valor, el valor medio o esperado del set de training.\n",
    "\n",
    "##### Por ello vemos que r2 score de Y Train es 0, y vemos que el modelo es inluso peor en testing, ya que toma valores negativos. \n",
    "\n",
    "##### La raíz cuadrada del error cuadrático medio llega alrededor de 300.000 para train y test. \n",
    " \n",
    "##### El modelo elegido debe tener mejores resultados que el de Benchmark.\n",
    "\n",
    "---\n",
    "\n",
    "#### A continuacón voy a entrenar y predecir con los siguientes modelos:\n",
    "\n",
    "- Regresión Linear\n",
    "\n",
    "- Árbol de Decisión (profundidades 1 a 25)\n",
    "\n",
    "- KNN Vecinos (1  5 10 15 20 25 30 35 40 45 50 vecinos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corro el modelo lineal\n",
    "model.run_all(model = 'linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A partir de la observación de las métricas, se puede afirmar que este modelo es mejor predictor que el modelo de Benchmark presentado anteriormente. Sin embargo, no considero que éste sea un buen modelo a aplicar.\n",
    "##### El R2 Score es  de 0.42, lo que indica que es bastante malo para predecir y se puede confirmar observando el RMSE, que es de 230.000 para test.\n",
    "##### En el Scatterplot de Y Test vs Y Test Predicted se puede observar que el modelo no se ajusta a los puntos del dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "##### **`NOTA PARA LOS PRÓXIMOS MODELOS: dentro de la función run_all, hay funciones que plotean diferencias de errores para cada modelo testeado y scatterplots de y test vs y test predicted. Para casos donde se testean varios modelos (como se vé a continuación) quizás sea más conveniente primero correr sólo el modelo y métricas, y luego plotear los modelos de interés. Sólo voy a usar la función run_all para mostrar su funcionamiento.`**\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corro el modelo de árboles de decisión\n",
    "model.run_all(model = 'tree', a = 1, b = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Considero que los modelos de árbol de decisión para profundidades de 15 a 20 son buenos predictores. Superan al modelo lineal y, por ende, también son muchísimo mejores que el Benchmark.\n",
    "##### En cuanto a la profundiad: a partir de depth = 16 la métrica de R2 Score de training se estabiliza y es de 0.88, lo que indica que es bastante bueno para predecir, lo que también se puede confirmar observando el RMSE, que es mucho menor al del modelo linear, y toma valores de 100.000 para train. Lo mismo ocurre para testing, donde R2 Score, menor al set de traning, es de 0.74 a partir de la profundidad 14 y su RMSE alrededor de 150.000.\n",
    "##### En el Scatterplot de Y Test vs Y Test Predicted se puede observar que el modelo se ajusta bastante bien a los puntos del dataset para las profundidades indicadas. \n",
    "##### El modelo elegido de los árboles de decisión es el de profundidad 16, ya que: la métrica de r2_score es la mejor para train y test, y no es necesario agregarle más complejidad, ya que no mejora ni r2_score ni se ven variaciones significativas en las otras métricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.run_all(model = 'knn', a = 1, b = 50, c = 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Vuelvo entrenar y predecir con el modelo KNN  para 1 a 10 vecinos, ya que entre estos valores de K encuentro los mejores valores de r2_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.run_all(model = 'knn', a= 1, b = 10, c = 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Considero que el modelo de vecinos cercanos con K = 4 es un predictor mejor al lineal y, por ende, al Benchmark, pero no mejor que el de árboles de decisión. \n",
    "##### La métrica de r2_score es de 0.8 para training y 0.7 para test, lo que indica que el modelo es relativamente bueno para predecir, y se justifica con sus RMSE que son de 133.000 para train y 165.000 para test.\n",
    "##### En el Scatterplot de Y Test vs Y Test Predicted se puede observar que el modelo se ajusta mejor que el lineal a los puntos del dataset, pero no tan bien si se lo compara con el de árboles de decisión.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `|` Modelo elegido:\n",
    "\n",
    "#### - Por las razones listadas anteriormente elijo como modelo predictor el modelo de `árboles de decisión con profundidad 16`, con variables predictoras X = ['rooms', 'bathrooms', surface_covered'] y variable a predecir y = 'price'\n",
    "\n",
    "\n",
    "Podría considerar correr el modelo sólo para la clase Departamento y comparar las méticas para concluir si hay o no diferencias significativas en la bondad de ajuste del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Esto es extra\n",
    "extra = pd.read_csv('DS_Proyecto_01_Datos_Properati.csv') \n",
    "extra = extra.query(\" l2 =='Capital Federal' & property_type in ['Departamento']\")\n",
    "extra = extra[['rooms', 'bedrooms','bathrooms', 'surface_total', 'surface_covered', 'price']] \n",
    "extra = extra.query(\"surface_total>=15 & surface_total<=1000 & price<=4000000\") \n",
    "extra.dropna(inplace=True)\n",
    "extra.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra = RegressionModels(extra, 'price', ['rooms', 'bathrooms', 'surface_covered'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra.Benchmark()\n",
    "extra.run_all(model = 'tree', a = 1,b = 20)\n",
    "extra.run_all(model = 'knn', a = 1, b = 10, c = 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusión:\n",
    "- A partir de la observación de las métricas, el mejor modelo para predecir es el de árboles de decisión con profundidad 15.\n",
    "- Este dataset filtrado por departamentos devuelve mejores predicciones que el filtrado por departamento, casa y ph. El r2_score en train es de 0.92 vs 0.88, y para test 0.83 vs 0.74. El RMSE en train es de 90.000 vs 100.000, y en test 134.000 vs 150.000."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
